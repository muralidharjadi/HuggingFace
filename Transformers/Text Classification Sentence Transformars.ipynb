{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d4bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd4cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\intel\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\intel\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5178d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>It is common knowledge that Karaims (but not K...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>, 12 April 2006 (UTC)\\nThen rewrite and expand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>\"I was trying to inject some humour (as eviden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxic\n",
       "996   It is common knowledge that Karaims (but not K...      0\n",
       "997   , 12 April 2006 (UTC)\\nThen rewrite and expand...      0\n",
       "998   \"I was trying to inject some humour (as eviden...      0\n",
       "999   And it looks like it was actually you who put ...      0\n",
       "1000  \"\\nAnd ... I really don't think you understand...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:\\\\Data\\\\NLP\\\\pradip\\\\toxic_commnets.csv\",on_bad_lines='error',skiprows = range(1000, 159570), engine=\"python\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c706ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'another', 'enough', 'does', 'this', 'make', 'made', 'most', 'may', 'onto', 'down', 'anywhere', 'we', 'whereby', 'amongst', 'that', 'eleven', 'have', 'since', 'twenty', 'alone', 'latter', 'less', 'latterly', 'be', 'what', 'not', 'side', 'under', 'its', 'when', 'were', 'some', 'as', 'show', 'thus', 'many', 'besides', 'become', 'least', 'eight', 'last', 'five', 'two', 'sometime', 'n’t', 'elsewhere', 'used', 'do', 'nor', 'few', 'been', 'empty', '’ve', 'hereafter', 'using', 'too', 'more', 'own', 'namely', 'former', 'four', 'already', 'anyway', 'either', 'him', 'each', 'an', 'afterwards', 'ours', 'these', 'much', 'somehow', 'say', 're', 'something', 'perhaps', 'sixty', 'about', 'from', 'towards', 'myself', 'nine', 'i', 'both', 'whether', \"n't\", 'along', 'beforehand', 'hers', 'also', 'often', 'neither', 'anything', 'next', 'you', 'whoever', 'sometimes', 'it', 'any', 'at', 'among', 'over', 'top', 'together', 'full', 'with', 'across', 'now', 'so', 'yours', 'whose', 'my', 'a', 'hereupon', 'moreover', 'she', '‘s', \"'re\", 'no', 'his', 'they', 'which', 'although', 'in', 'someone', 'nobody', 'would', 'he', 'becomes', 'out', 'might', 'everyone', 'everything', 'cannot', 'mine', 'one', 'wherever', 'quite', 'them', 'through', 'regarding', 'first', 'upon', 'twelve', 'whenever', 'thence', 'yet', 'thereafter', 'always', 'here', 'her', 'part', \"'ll\", \"'m\", 'your', 'thru', 'wherein', 'six', 'toward', 'herself', 'per', 'bottom', 'put', 'none', 'n‘t', 'see', 'where', 'whereupon', 'therein', '’m', '‘m', '’re', 'seems', 'becoming', 'could', 'ten', \"'s\", 'around', 'everywhere', 'please', \"'d\", 'still', 'every', 'to', 'name', 'front', 'within', 'beyond', 'noone', 'who', 'three', 'only', 'whole', 'others', 'take', '’ll', 'ourselves', 'several', 'very', 'due', 'indeed', 'below', 'all', 'for', 'call', 'us', 'am', 'hundred', 'then', 'whereas', 'done', 'hereby', 'throughout', 'by', 'is', 'their', 'between', 'otherwise', 'via', 'such', 'and', 'if', 'than', 'go', 'except', 'or', 'fifty', 'never', 'against', 'those', 'but', 'of', 'above', 'has', 'before', 'serious', 'give', '’d', 'me', '‘d', 'back', 'however', 'yourself', 'nevertheless', 'are', 'behind', 'beside', 'anyone', 'seem', 'keep', 'yourselves', 'formerly', 'without', 'once', 'get', 'should', 'further', 'really', 'though', 'can', 'amount', 'even', 'whither', 'nothing', 'itself', 'anyhow', 'how', 'while', 'himself', 'up', 'the', 'well', 'until', 'somewhere', 'there', 'move', 'being', 'seemed', 'after', \"'ve\", 'whatever', 'why', 'rather', 'mostly', 'off', 'almost', 'into', 'ca', 'forty', 'various', 'ever', 'must', 'on', 'thereby', 'because', 'meanwhile', 'became', 'whereafter', 'other', 'nowhere', 'third', 'will', 'during', 'again', 'herein', 'else', 'doing', '‘re', 'unless', 'themselves', 'was', '’s', 'seeming', 'our', 'whom', 'did', 'fifteen', 'whence', 'just', 'had', '‘ll', 'hence', 'therefore', 'same', 'thereupon', '‘ve'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff76d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7a2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "\n",
    "\n",
    "    # print(doc)\n",
    "    # print(type(doc))\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
    "\n",
    "    # print(mytokens)\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "    \n",
    "    sentence = \" \".join(mytokens)\n",
    "    # return preprocessed list of tokens\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68e230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour seemingly stick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man try edit war guy constantly remove rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>real suggestion improvement wonder section sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                            tokenize  \n",
       "0  explanation edit username hardcore metallica f...  \n",
       "1  d'aww match background colour seemingly stick ...  \n",
       "2  hey man try edit war guy constantly remove rel...  \n",
       "3  real suggestion improvement wonder section sta...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenize'] = data['comment_text'].apply(spacy_tokenizer)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73f06b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "      <td>[-0.030692976, 0.04184737, 0.041614547, 0.0137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour seemingly stick ...</td>\n",
       "      <td>[-0.053062137, 0.058449294, 0.04401034, -0.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man try edit war guy constantly remove rel...</td>\n",
       "      <td>[-0.0210479, 0.026711857, 0.0035101357, 0.0359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>real suggestion improvement wonder section sta...</td>\n",
       "      <td>[-0.047509685, -0.03601594, 0.04249648, 0.0576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>[-0.09303554, 0.008844826, -0.07133498, -0.007...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  explanation edit username hardcore metallica f...   \n",
       "1  d'aww match background colour seemingly stick ...   \n",
       "2  hey man try edit war guy constantly remove rel...   \n",
       "3  real suggestion improvement wonder section sta...   \n",
       "4                      sir hero chance remember page   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.030692976, 0.04184737, 0.041614547, 0.0137...  \n",
       "1  [-0.053062137, 0.058449294, 0.04401034, -0.005...  \n",
       "2  [-0.0210479, 0.026711857, 0.0035101357, 0.0359...  \n",
       "3  [-0.047509685, -0.03601594, 0.04249648, 0.0576...  \n",
       "4  [-0.09303554, 0.008844826, -0.07133498, -0.007...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['embeddings'] = data['tokenize'].apply(model.encode)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73035159",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['embeddings'].to_list()\n",
    "y = data['toxic'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d98b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f153a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7a55a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9203980099502488\n",
      "Logistic Regression Precision: 0.8571428571428571\n",
      "Logistic Regression Recall: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicted = LR.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05f062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
